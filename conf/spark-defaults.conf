# Default system properties included when running spark.
# This is useful for setting default environmental settings.

spark.io.compression.codec snappy
spark.sql.parquet.compression.codec snappy

# HDFS Integration
spark.hadoop.fs.defaultFS hdfs://namenode:9000

# Executor settings
spark.executor.memory 1g
spark.executor.cores 1
spark.executor.instances 2

# Driver settings
spark.driver.memory 2g
spark.driver.cores 1

# Serialization
spark.serializer org.apache.spark.serializer.KryoSerializer

# PostgreSQL JDBC driver for Spark SQL
spark.jars /opt/bitnami/spark/jars/postgresql-42.3.1.jar

# History server
spark.eventLog.enabled true
spark.eventLog.dir hdfs://namenode:9000/spark-logs
spark.history.fs.logDirectory hdfs://namenode:9000/spark-logs

# Shuffle service
spark.shuffle.service.enabled false

# Speculative execution
spark.speculation false

# Dynamic allocation
spark.dynamicAllocation.enabled false

# Memory fraction
spark.memory.fraction 0.6
spark.memory.storageFraction 0.5

# Network timeout
spark.network.timeout 120s

# Default parallelism
spark.default.parallelism 4


spark.ui.prometheus.enabled true    